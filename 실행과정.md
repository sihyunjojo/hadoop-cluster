# 핵심 플로우

1. 분산 저장: HDFS는 대용량 파일을 여러 DataNode에 분산 저장하여 안정성과 확장성을 제공합니다.
2. 분산 처리: Spark는 데이터를 여러 Executor에 분배하여 병렬로 처리함으로써 대규모 데이터 처리의 효율성을 높입니다.
3. 리소스 관리: YARN은 하둡 클러스터의 리소스를 효율적으로 관리하여 여러 애플리케이션이 동시에 실행될 수 있게 합니다.
4. 데이터 지역성: Spark는 가능한 한 데이터가 저장된 위치와 가까운 곳에서 처리를 수행하여 네트워크 부하를 줄입니다.

## HDFS에 저장되는 과정
1. CSV 파일 HDFS 업로드

1.1. 사용자가 Hadoop의 명령어를 사용하여 CSV 파일을 HDFS에 업로드합니다.

```bash
# username은 클러스터에서의 사용자 이름이고, hadoop-node-ip는 접속할 노드의 IP 주소입니다.
ssh username@hadoop-node-ip

# hadoop fs: HDFS와 상호작용하기 위한 명령어 집합의 시작
# -put: HDFS로 파일을 업로드하는 명령어
# /local/path/to/file.csv: 로컬 파일 시스템의 경로
# /hdfs/path/to/file.csv: HDFS 내의 논리적 파일 위치(목적지 경로)
hadoop fs -put /local/path/to/file.csv /hdfs/path/to/file.csv
```

- SSH를 통해 Hadoop 클러스터의 노드에 접속하여
- `hadoop fs -put` 명령어를 사용하는 것이 가장 간단하고 직접적인 방법입니다.
    - 실행하는 사용자에게 적절한 HDFS 권한이 있어야 합니다.

1.2. HDFS의 작동 방식:

- NameNode: 파일 시스템의 메타데이터를 관리합니다.
- DataNode: 실제 데이터를 저장합니다.

#### 업로드 과정

a) 클라이언트(예: Hadoop 명령어나 애플리케이션)가  NameNode에 파일 저장을 요청합니다.
b) NameNode는 파일을 저장할 DataNode들을 결정합니다. (이 목록을 클라이언트에게 반환합니다.)

c) 클라이언트는 NameNode에서 결정한 DataNode를 바탕으로 직접 DataNode들에 데이터를 전송합니다.

- 네임노드는 파일을 블록 단위(기본 128MB)로 나눕니다.
- 나눠서 블록 별로 저장합니다.

d) 데이터는 설정된 복제 팩터(일반적으로 3)에 따라 여러 DataNode에 복제됩니다.
- DataNode에 분산 저장하는 과정
    a) NameNode는 파일을 저장할 DataNode들의 목록을 결정합니다.
    b) 클라이언트는 첫 번째 블록을 첫 번째 DataNode로 전송 시작합니다.
    c) 동시에, 다른 블록들도 다른 DataNode들로 전송을 시작할 수 있습니다.
    d) 각 블록은 설정된 복제 팩터(보통 3)에 따라 여러 DataNode에 복제됩니다.
    - 여러 블록이 동시에 다른 DataNode 세트로 전송될 수 있습니다.
    - 예를 들어, 블록1은 DataNode1, 2, 3으로, 블록2는 DataNode4, 5, 6으로 동시에 전송될 수 있습니다.
    
- 결론적으로, CSV 파일의 블록들은 병렬적으로 처리되며, 6개의 DataNode에 효율적으로 분산 저장됩니다. 첫 번째 블록의 저장이 완료되기를 기다리지 않고 다른 블록들도 동시에 처리됩니다. 이 방식은 대용량 파일의 빠른 저장과 효율적인 분산 처리를 가능하게 합니다.

- 사용되지 않는 데이터노드들에 병렬로 저장이 이루어집니다.
- 네임노드는 각 블록에 대해 가장 적합한 데이터노드들을 선택합니다.
- 이 선택은 여러 요인(노드의 사용 가능한 공간, 네트워크 토폴로지, 현재 작업 부하 등)을 고려하여 이루어집니다.
  
e) 모든 복제가 완료되면 NameNode에 저장 완료를 알립니다.

f) NameNode는 파일의 메타데이터를 업데이트합니다.



## Spark의 내부 동작 과정
Spark 애플리케이션의 전체 실행 과정:

1. 애플리케이션 시작:
    - 사용자가 작성한 Spark 코드가 드라이버 프로그램으로 변환됩니다.
    - Spark 드라이버가 시작되고, SparkContext 또는 SparkSession이 초기화됩니다.
2. 리소스 요청 및 할당: (워커 노드에 리소스 할당)
    - 드라이버가 클러스터 매니저(예: YARN)에 리소스를 요청합니다.
    - 클러스터 매니저가 워커 노드에 리소스를 할당합니다.
    - 클러스터 매니저가 할당된 리소스 정보를 드라이버에게 전달합니다.
    - 드라이버는 할당받은 리소스를 바탕으로 Executor를 시작합니다.
3. 작업 계획 및 분할: (사용자 코드를 분석하여 작업을 태스크로 분할)
    - 드라이버가 사용자 코드를 분석하여 전체 작업을 DAG(Directed Acyclic Graph)로 변환합니다.
    - DAG를 여러 스테이지로 나눕니다.
    - 각 스테이지를 여러 **태스크**로 분할합니다.
4. 작업 분배 및 실행:
    - **드라이버가 생성된 태스크를 Executor들에게 직접 분배합니다.**
    - **Executor들이 할당받은 태스크를 실행합니다.**
5. 실행 제어 및 모니터링:
    - 드라이버가 전체 애플리케이션의 실행 흐름을 관리합니다.
    - 태스크의 진행 상황을 모니터링하고, 필요시 재시도 또는 재분배합니다.
6. 결과 수집 및 집계:
    - Executor들이 태스크 실행 결과를 드라이버에게 반환합니다.
    - 드라이버가 모든 Executor로부터 결과를 수집하고 집계합니다.
7. 애플리케이션 종료:
    - 모든 작업이 완료되면 드라이버가 SparkContext를 종료합니다.
    - 사용된 리소스가 클러스터 매니저에 반환됩니다.

이 과정에서 클러스터 매니저와 드라이버의 역할:

- 클러스터 매니저: 전체 클러스터의 리소스를 관리하고, Spark 애플리케이션에 필요한 리소스를 할당합니다.
- Spark 드라이버: 할당받은 리소스 내에서 작업을 계획하고, 태스크를 생성하여 Executor에 분배하며, 전체 실행 과정을 조율합니다.

이렇게 클러스터 매니저는 큰 그림에서 리소스를 관리하고, Spark 드라이버는 그 안에서 세부적인 작업 실행을 담당합니다. 두 요소가 협력하여 Spark 애플리케이션의 효율적인 분산 처리를 가능하게 합니다.

# 작업 분배 과정

1. 드라이버가 전체 작업을 DAG(Directed Acyclic Graph)로 변환합니다.
2. DAG를 여러 스테이지로 나눕니다.
3. 각 스테이지를 여러 태스크로 분할합니다.
4. 태스크를 클러스터의 실행기들에게 할당합니다.

# 리소스 할당 과정

a) Spark 드라이버가 클러스터 매니저에게 리소스를 요청합니다.
b) 클러스터 매니저가 워커 노드에 리소스를 할당합니다.
c) 클러스터 매니저가 할당된 리소스 정보를 Spark 드라이버에게 전달합니다.
d) Spark 드라이버는 할당받은 리소스(Executor) 내에서 태스크를 실행합니다.

# 작업 실행 과정

a) Spark 드라이버가 작업을 스테이지와 태스크로 나눕니다.
b) 드라이버가 할당받은 Executor들에게 직접 태스크를 분배합니다.
c) Executor들이 태스크를 실행하고 결과를 드라이버에게 반환합니다.

# Spark 애플리케이션과 드라이버의 관계

1. 애플리케이션 시작: 사용자가 작성한 Spark 코드가 드라이버 프로그램으로 변환됩니다.
2. 실행 제어: 드라이버가 애플리케이션의 실행 흐름을 관리합니다.
3. 리소스 요청: 드라이버가 클러스터 매니저에 리소스를 요청합니다.
4. 작업 분배: 드라이버가 작업을 Executor들에게 분배합니다.
5. 결과 수집: 드라이버가 Executor들로부터 결과를 수집하고 집계합니다.
